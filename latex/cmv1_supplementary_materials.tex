\documentclass[a4paper]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage[margin=1in]{geometry}
%\documentclass[12pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{textcomp}
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ...
%\geometry{landscape}                		% Activate for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
\usepackage{caption}
\usepackage{subcaption}								% TeX will automatically convert eps --> pdf in pdflatex
\usepackage{color}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{listings}
\usepackage{url}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\usepackage{natbib}
\usepackage{xcolor}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{hyperref}
% removed hyperref because of arXiv complaining
\usepackage{authblk}
\usepackage{float}
\usepackage{rotating}
\usepackage{adjustbox}
\usepackage[font=small,labelfont=bf]{caption}
%\usepackage{changes}
\usepackage{changes}
\definechangesauthor[name={George Chacko}, color=blue]{gc}

\renewcommand{\thealgorithm}{S\arabic{algorithm}}
\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thetable}{S\arabic{table}}
\renewcommand{\thesection}{S\arabic{section}}
\renewcommand{\theequation}{S\arabic{equation}}
\renewcommand{\thetheorem}{S\arabic{theorem}}
\renewcommand{\thelemma}{S\arabic{lemma}}

\hypersetup{
     colorlinks=true,
     linkcolor=blue,
     filecolor=blue,
     citecolor = blue,
     urlcolor=blue,
     }


\usepackage{authblk}
\title{Supplementary Materials for ``Well-Connected Communities in Real-World Networks''}
\author[1]{Minhyuk Park\thanks{Minhyuk Park and Yasamin Tabatabaee contributed equally}}
\author[1]{Yasamin Tabatabaee}
\author[1]{Baqiao Liu}
\author[1]{Vidya Kamath Pailodi\thanks{Vidya Kamath Pailodi and Vikram Ramavarapu contributed equally}}
\author[1]{Vikram Ramavarapu}
\author[1]{Rajiv Ramachandran}
\author[2]{Dmitriy Korobskiy}
\author[3]{Fabio Ayres}
\author[1,4]{George Chacko\thanks{chackoge@illinois.edu}}
\author[1]{Tandy Warnow\thanks{warnow@illinois.edu}}
\affil[1]{Department of Computer Science, University of Illinois Urbana-Champaign, Urbana, IL 61801, USA}
\affil[2]{NTT DATA, McLean, VA 22102, USA}
\affil[3]{Insper Institute, S\={a}o Paulo, Brazil}
\affil[4]{Office of Research, Grainger College of Engineering, University of Illinois Urbana-Champaign, Urbana, IL 61801, USA}


\begin{document}
\maketitle
\tableofcontents
\listoffigures
\listoftables
\newpage


\section{Connectivity Modifier Pipeline}

In this section, we bring the details of each step of the pipeline, in addition to commands.

\subsection{Details about the pipeline}

\begin{itemize}
\item Scripts used for analysis in this study are available at\\
 \href{https://github.com/illinois-or-research-analytics/cm_manuscript/tree/main/analysis}{https://github.com/illinois-or-research-analytics/cm\_manuscript/tree/main/analysis}.
 \item The CM code is available at\\
 \href{https://github.com/RuneBlaze/connectivity-modifier}{https://github.com/RuneBlaze/connectivity-modifier}.\\
 \href{https://pypi.org/project/connectivity-modifier/}{https://pypi.org/project/connectivity-modifier/}.
 \end{itemize}

\subsubsection*{Preprocessing the network}
Before running the CM pipeline, we removed duplicate/parallel edges and self-loops from the networks, using the \texttt{cleanup\_el.R} script with the following command:

\begin{lstlisting}[basicstyle=\ttfamily\small]
Rscript cleanup_el.R <original_network.tsv> <cleaned_network.tsv>
\end{lstlisting}

\subsubsection*{CM Pipeline}
The cleaned input network $\mathcal{G}$ is then processed in a pipeline that has the following stages:
\begin{itemize}
\item \textbf{Clustering}: Clustering $\mathcal{G}$, using either the Leiden algorithm (in default mode with two iterations) or Iterative K-core Clustering (IKC) method, with the following commands respectively:

\begin{lstlisting}[basicstyle=\ttfamily\small]
leidenalg.find_partition(net, leidenalg.CPMVertexPartition, resolution_parameter=r)
\end{lstlisting}

\begin{lstlisting}[basicstyle=\ttfamily\small]
IKC.py -e <cleaned_network.tsv> -k 10 -o <output file>
\end{lstlisting}

We used the Python version of Leiden (leidenalg v0.8.2) available at \cite{leiden-code} and
%\href{https://github.com/vtraag/leidenalg}{https://github.com/vtraag/leidenalg} and
IKC (v1.0.0) available at \cite{ikc-code}.

 %\href{https://github.com/chackoge/ERNIE_Plus/blob/master/Illinois/clustering/eleanor/code/IKC.py}{https://github.com/chackoge/ERNIE\_Plus/blob/master/Illinois/clustering/} \href{https://github.com/chackoge/ERNIE_Plus/blob/master/Illinois/clustering/eleanor/code/IKC.py}{eleanor/code/IKC.py}.


\item  \textbf{Filtering}: Removing clusters of size less than or equal to 10 as well as trees (defined as connected clusters where the number $m$ of edges is one less than the number $n$ of vertices, so that $m=n-1$).

Each of the  following options can be used to perform this step: 
\begin{enumerate}
\item \texttt{belinda} \citep{belinda2022} expressions, e.g., \texttt{g1.filter(pl.col('n') > 10)} and \texttt{g1.filter(pl.col('n') != pl.col('m') + 1)}
\item \texttt{find\_trees.py}: a slow script that relies on Networkit \citep{Staudt2016}
\item \texttt{cluster\_analyzer.py}: a parallelized version of find\_trees.py
\item \texttt{subset\_graph\_nonnetworkit.R}: a fast script without dependence on Networkit that also returns maxDegree for a cluster.
\end{enumerate}
}
\item  \textbf{CM}: Applying connectivity modifier, available at \cite{cm2022} (however, also see Section \ref{sec:cm-codes} for additional software for CM)
 %\href{https://github.com/RuneBlaze/connectivity-modifier}{https://github.com/RuneBlaze/connectivity-modifier}
 with the following commands (assuming the clustering method used is Leiden), where the option \texttt{-g} specifies the resolution parameter:
\begin{lstlisting}[basicstyle=\ttfamily\small]
$ cm -i <cleaned_network.tsv> -c leiden -e <filtered_leiden_clustering.tsv> -g <r>
-t 1log10 -o <cm_output.tsv>
$ cm2universal -g <cleaned_network.tsv> -i <cm_output.tsv> -o <cm_output.tsv>
\end{lstlisting}
\item \textbf{Filtering}: Removing clusters of size at most 10. using the same commands as the first filtering step.
\begin{enumerate}
\item \texttt{belinda} \citep{belinda2022} expressions, e.g., \texttt{g1.filter(pl.col('n') > 10)} and \texttt{g1.filter(pl.col('n') != pl.col('m') + 1)}
\item \texttt{post\_cm\_filter.R}: a simple script that removes all clusters of size 10 or less.
\end{enumerate}
\end{itemize}

We note also that in some analyses reported in the paper, we first removed the clusters of size at most 10, before proceeding with filtering; this allows us
to count the number of clusters of size at least 11 that are trees.



\paragraph{Pseudocode for the Connectivity Modifier}
The input to the Connectivity Modifier (CM) is a network and a  clustering; the output will be a set of well-connected clusters (WCC), obtained
by processing each cluster in the input.
Thus, each cluster in the output WCC will be a subset of one of the input clusters.
Here we describe CM, beginning  with the necessary definitions.

\begin{itemize}
    \item $\delta(C)$: the minimum degree of  any node in cluster $C$
    \item $deg(u)$: the degree of node $u$
    \item $t(C)$: minimum required edge cut size for  $C$
    \item $\lambda(C)$: the minimum edge cut size of $C$
    \item $mod(C, H)$: modularity of subgraph $H$ with respect to $C$, assuming $H \subseteq C$
    \item $f$: clustering method: a clustering method takes as input a graph, and outputs non-singleton subgraphs of the input graph.
\end{itemize}

Recall that  $t(C)$ is the {\em smallest} cut that can still be considered ``large enough".
Furthermore, in our experiments, we set $t(C) = \lfloor \log_{10}(n) \rfloor +1$.  This means that any edge cut that has fewer than $t(C)$ edges
will be considered small, and so will be removed from the graph.
Here we explore the effect of this definition of $t(C)$, where $C$ is a cluster with $n$ vertices.
\begin{itemize}
\item
$1 \leq n \leq 9$.
For all values of $n$ in this range, we obtain $t(C) = \lfloor log_{10}(n) \rfloor +1$, and so $t(C) = 1$.  Hence, for $1 \leq n \leq 9$, we  only require that the
cluster be connected.
\item
$10 \leq n \leq 99$. For all values of $n$ in this range, we have
 $t(C) = 2$, which means that if $C$ is a cluster of size $n$ and it has an edge cut of size $1$, that  cut will
be considered ``too small", and will be removed from the graph.  Effectively this only ensures that clusters of size between $10$ and $99$ do not have cut edges.
If a cut edge is found, it will mean that in the CM code, that cut edge will be deleted, thus separating the cluster into two pieces.
In contrast, a cut of size $2$ will be considered large enough, and will not be removed.
\item
$100 \leq n \leq 999$.
For all values of $n$ in this range, we have $t(C)=3$, which means that if $C$ has a cut of size  at most $2$ it will be considered
too small, and any such cut will be deleted from $C$.
In contrast, a cut of size $3$  or larger will be considered large enough, and will not be removed.
\item
$1000 \leq n \leq 9999$.
For all values of $n$ in this range, we have $t(C)=4$, which means that if $C$ has a cut of size $3$ or smaller it will be considered
too small, and any such cut will be deleted from $C$.
In contrast, a cut of size $4$ or larger will be considered large enough, and will not be removed.
\end{itemize}

\clearpage
\begin{algorithm}[h]
\caption{Pseudocode for min-cut validity pipeline. The input is a network $\mathcal{G}$ with $N$ vertices and a clustering method $f$ (e.g. Leiden, IKC), and the output is a set of well-connected clusters WCC.}
\begin{algorithmic}[2]
\State $f$: Clustering method (e.g., IKC, Leiden, etc.)
\Function{$g$}{$\mathcal{G}$}
\State WCC $\gets []$ \Comment{This is an empty array}

\State clusters $\gets f(\mathcal{G})$ \Comment{This is an array of clusters generated by $f$}
\State stack $\gets$ clusters
\While{!stack.empty()} \Comment{While there is a cluster in the stack}
    \State $H$ = stack.pop()
    \While{$\delta(H) < t(H)$}
    \State delete an arbitrary node $u$ from $H$ where $deg(u) = \delta(H)$
    \EndWhile
    \If{$\lambda(H) < t(H)$} \Comment{If the edge cut for H is smaller than $t$}
        \State $H_a, H_b$ $\gets$ $H$ separated by a minimum cut
        \State stack.extend($f(H_a)$) \Comment{Recluster $H_a$ and $H_b$}
        \State stack.extend($f(H_b)$)  \Comment{and add clusters to stack}
    \Else
       % \If{$f$ is not modified IKC $\lor$ $mod(G, H) \ge 0$}
            \State WCC $\gets$ WCC $+$ [$H$] \Comment{Add H to WCC}
        \EndIf
\EndWhile
%\If{$f = $ IKC}
%    \State remove all clusters from ans that have modularity $\leq 0$
%    \EndIf
%\textcolor{blue}{}
\State \Return WCC \Comment{WCC contains only well-connected clusters}
\EndFunction
\end{algorithmic}

\label{alg:full-pipeline}
\end{algorithm}

\textbf{Notes:}
\begin{itemize}
\item When
$f$ (the clustering method) is IKC, we have made a small modification to the
code for the sake of efficiency.
Specifically, IKC requires that all the clusters have positive modularity.
 In our CM code, the recursive
calls to the clustering method (IKC) in lines 13 and 14 do not check for positive modularity; instead, this check is delayed until the stack is empty (i.e., after line 18).
At this point, it is possible that some of the clusters in WCC will not have positive modularity.
Therefore, when we run CM with IKC for the clustering method $f$,  we add a processing step after line 18 that checks each cluster in WCC for positive modularity,
and deletes any cluster that fails this test.
Only after pruning all such clusters from WCC will we return what is left.
\item If desired, the clustering method $f$ can be a modified version of a standard method, such as Leiden, where the clusters below size $B$ are deleted before being further processed in the pipeline.
\end{itemize}

\subsection{Evolution of the CM pipeline}
\label{sec:cm-codes}

The first version of the CM pipeline was developed by Baqiao Liu and Minhyuk Park, as part of a project for a graduate course at the University of Illinois Urbana-Champaign. This work was also supported, 
in part, by the partnership between the Insper Institute in Sao Paulo, Brazil and the University of Illinois Urbana-Champaign. Code from this effort is available at \cite{cm2022} and is fully functional. In this version, 
preprocessing of existing clusterings and post-processing of CM output is handled by Belinda \citep{belinda2022}.

Subsequent extensions to the original CM code for its use with Leiden clustering have been made by Vikram Ramavarapu, and Fabio Ayres. These new versions are more performant but are 
algorithmically identical so that any changes in output are due only to randomness. Vidya Kamath Pailodi developed a modular pipeline that is being used to test and facilitate 
continuous integration of these extensions. Both the pipeline and later versions of the CM code were used to generate data for this manuscript. We used the original  CM code for all IKC-based pipelines, 
and the new codes for some of the Leiden-based analysis.}. Code for the pipeline and extended CM are available at \cite{cm_pipe2023}. Details of the extensions, the pipeline, and evaluation will be 
made available in a manuscript that is presently under preparation.

\clearpage
\section{Emulating Real Networks with LFR Graphs}
 The code for estimating the parameters of a pair of network and clustering and generating an LFR benchmark graph that represents their properties is available at \href{https://github.com/illinois-or-research-analytics/cm_manuscript/tree/main/analysis/lfr-analysis}{https://github.com/illinois-or-research-analytics/} \href{https://github.com/illinois-or-research-analytics/cm_manuscript/tree/main/analysis/lfr-analysis}{cm\_manuscript/tree/main/analysis/lfr-analysis} and was used with the following commands. Further development of this work
  will be available at \href{https://github.com/ytabatabaee/emulate-real-nets}{https://github.com/ytabatabaee/emulate-real-nets}:
 

\begin{lstlisting}[basicstyle=\ttfamily\small]
python3 estimate_properties.py -n <network.tsv> -c <clustering_memberships.tsv>
\end{lstlisting}
that produces a json file containing all parameters of the network/clustering pair and then this json file is used to generate an LFR graph as follows

\begin{lstlisting}[basicstyle=\ttfamily\small]
python3 gen_lfr.py -n <clustering_memberships.json> -lp <lfr-benchmark-software-path>
-cm <cmin_value>
\end{lstlisting}

\noindent
in which the LFR software \citep{lancichinetti2008benchmark} is used with the following command:

\begin{lstlisting}[basicstyle=\ttfamily\small]
./binary_networks/benchmark -N <node-count> -k <avg-degree>
                            -maxk <max-degree> -mu <mixing-parameter>
                            -maxc <max-cluster-size> -minc <min-cluster-size>
                            -t1 <degree-exponent> -t2 <comm-size-exponent>
\end{lstlisting}



As suggested previously \citep{hagberg2008exploring}, a somewhat limited range of parameters can be used to successfully generate an LFR graph. Due to restrictions of the LFR methodology, we made the following adjustments in our experiments for emulating our collection of empirical networks:

\begin{itemize}
    \item LFR software is not scalable to large networks, and therefore we emulated the two largest networks (Open Citations and CEN) with LFR graphs with 3,000,000 nodes, and adjusted the maximum degree and maximum community size accordingly.
    \item The Wikipedia talk network has a very small average degree of 3.89, a maximum degree of 100029, and an estimated power-law degree exponent of 1.90. Based on the assumptions of the LFR methodology, we had to reduce the input maximum degree (\texttt{maxk}) to 31, as for the given average degree, any value above this for \texttt{maxk} resulted in an error from the LFR software.
    \item In all our real networks with all resolution parameters, the minimum community size was 1, as singletons were always present in the empirical networks. However, the LFR methodology assumes that all nodes are in a valid community. In most cases, by setting (\texttt{minc}) equal to 1, the LFR software either took very long to run (more than our time limit of 4 hours per network), or could not generate the community size distribution with the given properties at all. Therefore, with the exception of high energy physics citation network for which \texttt{minc} = 1 successfully generated the LFR, for other networks, we found the \textit{minimum} value of \texttt{minc} that generated the LFR graph in less than 4 hours with a brute-force search (exploring all values of \texttt{minc} starting from 1, to the point where the LFR was generated in the given time limit).
\end{itemize}

Figures \ref{fig:all-degrees} to \ref{fig:wiki_topcats_cm_size} show a comparison between the degree distribution and community size distributions of the six empirical networks and their corresponding LFR graphs for different resolution values. Table \ref{table:all-params} shows various parameters of the empirical networks and their corresponding LFR graphs.

\begin{table}[h!]
\caption[Properties of the empirical networks and their LFR model graphs.]{Properties of the empirical networks and their LFR model graphs.  Parameters: $r$ stands for resolution value used for generating the Leiden clustering, $\mu$ stands for the mixing parameter, and $\tau_1$ and $\tau_2$ are the \textit{estimated} power-law exponents for the degree and the community size distributions respectively.}
\centering
\begin{tabular}{lrrrrrrr}
\hline
network              & $r$      & nodes      & edges         & average degree & $\mu$    & $\tau_1$  & $\tau_2$  \\ \hline \hline
open\_citations      & 0.0001 & 75,025,194 & 1,363,303,678 & 36.34    & 0.407 & 2.974 & 4.025 \\
open\_citations\_LFR & 0.0001 & 3,000,000  & 55,134,611    & 36.76    & 0.407 & 2.978 & 4.027 \\\hline
open\_citations      & 0.001  & 75,025,194 & 1,363,303,678 & 36.34    & 0.500 & 2.974 & 4.607 \\
open\_citations\_LFR & 0.001  & 3,000,000  & 54,946,186    & 36.63    & 0.501 & 2.982 & 4.603 \\ \hline
open\_citations      & 0.01   & 75,025,194 & 1,363,303,678 & 36.34    & 0.602 & 2.974 & 2.079 \\
open\_citations\_LFR & 0.01   & 3,000,000  & 55,135,215    & 36.76    & 0.602 & 2.978 & 2.110 \\ \hline
open\_citations      & 0.1    & 75,025,194 & 1,363,303,678 & 36.34    & 0.711 & 2.974 & 6.254 \\
open\_citations\_LFR & 0.1    & 3,000,000  & 54,911,549    & 36.61    & 0.711 & 2.980 & 6.241 \\ \hline
open\_citations      & 0.5    & 75,025,194 & 1,363,303,678 & 36.34    & 0.871 & 2.974 & 6.137 \\
open\_citations\_LFR & 0.5    & 3,000,000  & 55,114,185    & 36.74    & 0.871 & 2.978 & 6.135 \\ \hline\hline
CEN      & 0.001 & 13,989,436 & 92,051,051 & 13.16    & 0.522 & 2.618 & 2.363 \\
CEN\_LFR & 0.001 & 3,000,000  & 20,819,461 & 13.88    & 0.522 & 2.621 & 2.366 \\ \hline
CEN      & 0.01  & 13,989,436 & 92,051,051 & 13.16    & 0.645 & 2.618 & 2.743 \\
CEN\_LFR & 0.01  & 3,000,000  & 20,762,221 & 13.84    & 0.645 & 2.621 & 2.746 \\ \hline
CEN      & 0.1   & 13,989,436 & 92,051,051 & 13.16    & 0.880 & 2.618 & 4.652 \\
CEN\_LFR & 0.1   & 3,000,000  & 20,712,745 & 13.81    & 0.878 & 2.625 & 4.630 \\ \hline
CEN      & 0.5   & 13,989,436 & 92,051,051 & 13.16    & 0.988 & 2.618 & 3.271 \\
CEN\_LFR & 0.5   & 3,000,000  & 20,821,434 & 13.88    & 0.988 & 2.620 & 3.311 \\ \hline \hline
cit\_patents      & 0.001 & 3,774,768 & 16,518,947 & 8.75     & 0.284 & 4.017 & 4.993 \\
cit\_patents\_LFR & 0.001 & 3,774,768 & 15,641,679 & 8.29     & 0.284 & 4.025 & 5.011 \\ \hline
cit\_patents      & 0.01  & 3,774,768 & 16,518,947 & 8.75     & 0.382 & 4.017 & 2.570 \\
cit\_patents\_LFR & 0.01  & 3,774,768 & 15,640,122 & 8.29     & 0.382 & 4.000 & 2.577 \\ \hline
cit\_patents      & 0.1   & 3,774,768 & 16,518,947 & 8.75     & 0.511 & 4.017 & 4.629 \\
cit\_patents\_LFR & 0.1   & 3,774,768 & 15,643,140 & 8.29     & 0.511 & 4.009 & 4.613 \\ \hline
cit\_patents      & 0.5   & 3,774,768 & 16,518,947 & 8.75     & 0.805 & 4.017 & 4.212 \\
cit\_patents\_LFR & 0.5   & 3,774,768 & 15,605,570 & 8.27     & 0.807 & 4.005 & 4.154 \\ \hline \hline
cit\_hepph      & 0.001 & 34,546 & 420,877 & 24.37    & 0.221 & 3.631 & 1.439 \\
cit\_hepph\_LFR & 0.001 & 34,546 & 431,138 & 24.96    & 0.221 & 3.632 & 1.605 \\ \hline
cit\_hepph      & 0.01  & 34,546 & 420,877 & 24.37    & 0.380 & 3.631 & 1.850 \\
cit\_hepph\_LFR & 0.01  & 34,546 & 431,127 & 24.96    & 0.380 & 3.632 & 2.063 \\ \hline
cit\_hepph      & 0.1   & 34,546 & 420,877 & 24.37    & 0.569 & 3.631 & 2.328 \\
cit\_hepph\_LFR & 0.1   & 34,546 & 431,138 & 24.96    & 0.569 & 3.632 & 4.212 \\ \hline
cit\_hepph      & 0.5   & 34,546 & 420,877 & 24.37    & 0.781 & 3.631 & 2.786 \\
cit\_hepph\_LFR & 0.5   & 34,546 & 431,138 & 24.96    & 0.781 & 3.632 & 3.627 \\ \hline \hline
wiki\_topcats      & 0.001 & 1,791,489 & 25,444,207 & 28.41    & 0.546 & 2.430 & 1.936 \\
wiki\_topcats\_LFR & 0.001 & 1,791,489 & 24,576,247 & 27.44    & 0.546 & 2.439 & 1.954 \\ \hline
wiki\_topcats      & 0.01  & 1,791,489 & 25,444,207 & 28.41    & 0.682 & 2.430 & 2.422 \\
wiki\_topcats\_LFR & 0.01  & 1,791,489 & 24,494,292 & 27.35    & 0.682 & 2.441 & 2.422 \\ \hline
wiki\_topcats      & 0.1   & 1,791,489 & 25,444,207 & 28.41    & 0.791 & 2.430 & 3.311 \\
wiki\_topcats\_LFR & 0.1   & 1,791,489 & 24,255,498 & 27.08    & 0.792 & 2.442 & 3.305 \\ \hline
wiki\_topcats      & 0.5   & 1,791,489 & 25,444,207 & 28.41    & 0.902 & 2.430 & 4.048 \\
wiki\_topcats\_LFR & 0.5   & 1,791,489 & 24,332,705 & 27.16    & 0.903 & 2.442 & 4.058 \\ \hline \hline
wiki\_talk      & 0.001 & 2,394,385 & 4,659,565 & 3.89     & 0.357 & 1.901 & 1.861 \\
wiki\_talk\_LFR & 0.001 & 2,394,385 & 3,304,671 & 2.76     & 0.355 & 2.073 & 1.874 \\ \hline
wiki\_talk      & 0.01  & 2,394,385 & 4,659,565 & 3.89     & 0.753 & 1.901 & 1.917 \\
wiki\_talk\_LFR & 0.01  & 2,394,385 & 3,297,391 & 2.75     & 0.752 & 2.062 & 2.261 \\ \hline
wiki\_talk      & 0.1   & 2,394,385 & 4,659,565 & 3.89     & 0.941 & 1.901 & 2.034 \\
wiki\_talk\_LFR & 0.1   & 2,394,385 & 3,296,122 & 2.75     & 0.940 & 2.062 & 2.188 \\ \hline
wiki\_talk      & 0.5   & 2,394,385 & 4,659,565 & 3.89     & 0.984 & 1.901 & 2.931 \\ \hline
\end{tabular}
\label{table:all-params}
\end{table}

 \clearpage
%\textcolor{red}{write the math behind fitting power-law}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\linewidth]{figs/all_degrees.pdf}
\caption[Comparison between the degree distribution of empirical and LFR networks.]{\textbf{Comparison between the degree distribution of empirical and LFR networks.} The LFR networks are produced to emulate the characteristics of their corresponding real network. For the CEN and the OpenCitations network, the number of nodes of the LFR network is 3,000,000, and for the other networks it exactly matches the number of nodes in its corresponding empirical network. The resolution parameter used for generating the LFR graphs shown in this figure is 0.01. }
\label{fig:all-degrees}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\linewidth]{figs/oc_cm_size.pdf}
\caption[Cluster size distribution for Open Citations networks.]{\textbf{Cluster size distribution for Open Citations networks.} The LFR ground-truth communities (shown in green) are generated according to the parameters estimated from the Leiden clustering of the empirical network (in black), and then the LFR network is re-clustered using Leiden with the same resolution value. }
\label{fig:oc_cm_size}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\linewidth]{figs/cen_cm_size.pdf}
\caption[Cluster size distribution for CEN citation networks.]{\textbf{Cluster size distribution for CEN citation networks.} The LFR ground-truth communities (shown in green) are generated according to the parameters estimated from the Leiden clustering of the empirical network (in black), and then the LFR network is re-clustered using Leiden with the same resolution value. }
\label{fig:cen_cm_size}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\linewidth]{figs/cit_patents_cm_size.pdf}
\caption[Cluster size distribution for US patents citation networks.]{\textbf{Cluster size distribution for US patents citation networks.} The LFR ground-truth communities (shown in green) are generated according to the parameters estimated from the Leiden clustering of the empirical network (in black), and then the LFR network is re-clustered using Leiden with the same resolution value. }
\label{fig:cit_patents_cm_size}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\linewidth]{figs/cit_hepph_cm_size.pdf}
\caption[Cluster size distribution for High Energy physics citation networks.]{\textbf{Cluster size distribution for High Energy physics citation networks.} The LFR ground-truth communities (shown in green) are generated according to the parameters estimated from the Leiden clustering of the empirical network (in black), and then the LFR network is re-clustered using Leiden with the same resolution value. }
\label{fig:cit_hepph_cm_size}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[width=0.85\linewidth]{figs/wiki_topcats_cm_size.pdf}
\caption[Cluster size distribution for Wikipedia hyperlink networks.]{\textbf{Cluster size distribution for Wikipedia hyperlink (wiki\_topcats) networks.} The LFR ground-truth communities (shown in green) are generated according to the parameters estimated from the Leiden clustering of the empirical network (in black), and then the LFR network is re-clustered using Leiden with the same resolution value. }
\label{fig:wiki_topcats_cm_size}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\linewidth]{figs/wiki_talk_cm_size.pdf}
\caption[Cluster size distribution for Wikipedia talk networks.]{\textbf{Cluster size distribution for Wikipedia talk networks.} The LFR ground-truth communities (shown in green) are generated according to the parameters estimated from the Leiden clustering of the empirical network (in black), and then the LFR network is re-clustered using Leiden with the same resolution value. We were not able to generate an LFR graph for the highest resolution value ($r = 0.5$).}
\label{fig:wiki_talk_cm_size}
\end{figure}

\clearpage

\section{Additional Results for the CM pipeline}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/oc_cm_steps_lfr0001.pdf}
\includegraphics[width=0.37\textwidth]{figs/oc_0001_cm_size.pdf}
\caption[CM pipeline on the empirical Open Citations network and its model LFR graph for r=0.0001]{\textbf{CM pipeline on the empirical Open Citations network and its model LFR graph for r=0.0001.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:oc-cm-lfr-0001}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/oc_cm_steps_lfr01.pdf}
\includegraphics[width=0.37\textwidth]{figs/oc_01_cm_size.pdf}
\caption[CM pipeline on the empirical Open Citations network and its model LFR graph for r=0.01]{\textbf{CM pipeline on the empirical Open Citations network and its model LFR graph for r=0.01.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:oc-cm-lfr-01}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/oc_cm_steps_lfr1.pdf}
\includegraphics[width=0.37\textwidth]{figs/oc_1_cm_size.pdf}
\caption[CM pipeline on the empirical Open Citations network and its model LFR graph for r=0.1]{\textbf{CM pipeline on the empirical Open Citations network and its model LFR graph for r=0.1.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:oc-cm-lfr-1}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/oc_cm_steps_lfr5.pdf}
\includegraphics[width=0.37\textwidth]{figs/oc_5_cm_size.pdf}
\caption[CM pipeline on the empirical Open Citations network and its model LFR graph for r=0.5]{\textbf{CM pipeline on the empirical Open Citations network and its model LFR graph for r=0.5.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:oc-cm-lfr-5}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/cen_cm_steps_lfr001.pdf}
\includegraphics[width=0.37\textwidth]{figs/cen_001_cm_size.pdf}
\caption[CM pipeline on the empirical CEN network and its model LFR graph for r=0.001]{\textbf{CM pipeline on the empirical CEN network and its model LFR graph for r=0.001.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:cen-cm-lfr-001}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/cen_cm_steps_lfr1.pdf}
\includegraphics[width=0.37\textwidth]{figs/cen_1_cm_size.pdf}
\caption[CM pipeline on the empirical CEN network and its model LFR graph for r=0.1]{\textbf{CM pipeline on the empirical CEN network and its model LFR graph for r=0.1.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:cen-cm-lfr-1}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/cen_cm_steps_lfr5.pdf}
\includegraphics[width=0.37\textwidth]{figs/cen_5_cm_size.pdf}
\caption[CM pipeline on the empirical CEN network and its model LFR graph for r=0.5]{\textbf{CM pipeline on the empirical CEN network and its model LFR graph for r=0.5.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:cen-cm-lfr-5}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/cit_patents_cm_steps_lfr001.pdf}
\includegraphics[width=0.37\textwidth]{figs/cit_patents_001_cm_size.pdf}
\caption[CM pipeline on the empirical citation patents network and its model LFR graph for r=0.001]{\textbf{CM pipeline on the empirical citation patents network and its model LFR graph for r=0.001.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:patents-cm-lfr-001}
\end{figure}


\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/cit_patents_cm_steps_lfr1.pdf}
\includegraphics[width=0.37\textwidth]{figs/cit_patents_1_cm_size.pdf}
\caption[CM pipeline on the empirical citation patents network and its model LFR graph for r=0.1]{\textbf{CM pipeline on the empirical citation patents network and its model LFR graph for r=0.1.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:patents-cm-lfr-1}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/cit_patents_cm_steps_lfr5.pdf}
\includegraphics[width=0.37\textwidth]{figs/cit_patents_5_cm_size.pdf}
\caption[CM pipeline on the empirical citation patents network and its model LFR graph for r=0.5]{\textbf{CM pipeline on the empirical citation patents network and its model LFR graph for r=0.5.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:patents-cm-lfr-5}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/cit_hepph_cm_steps_lfr001.pdf}
\includegraphics[width=0.37\textwidth]{figs/cit_hepph_001_cm_size.pdf}
\caption[CM pipeline on the empirical high energy physics citation network and its model LFR graph for r=0.001]{\textbf{CM pipeline on the empirical high energy physics citation network and its model LFR graph for r=0.001.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:hepph-cm-lfr-001}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/cit_hepph_cm_steps_lfr01.pdf}
\includegraphics[width=0.37\textwidth]{figs/cit_hepph_01_cm_size.pdf}
\caption[CM pipeline on the empirical high energy  physics citation network and its model LFR graph for r=0.01]{\textbf{CM pipeline on the empirical high energy physics citation network and its model LFR graph for r=0.01.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:hepph-cm-lfr-01}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/cit_hepph_cm_steps_lfr1.pdf}
\includegraphics[width=0.37\textwidth]{figs/cit_hepph_1_cm_size.pdf}
\caption[CM pipeline on the empirical high energy  physics citation network and its model LFR graph for r=0.1]{\textbf{CM pipeline on the empirical high energy physics citation network and its model LFR graph for r=0.1.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:hepph-cm-lfr-1}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/cit_hepph_cm_steps_lfr5.pdf}
\includegraphics[width=0.37\textwidth]{figs/cit_hepph_5_cm_size.pdf}
\caption[CM pipeline on the empirical high energy  physics citation network and its model LFR graph for r=0.5]{\textbf{CM pipeline on the empirical high energy physics citation network and its model LFR graph for r=0.5.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:hepph-cm-lfr-5}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/wiki_topcats_cm_steps_lfr001.pdf}
\includegraphics[width=0.37\textwidth]{figs/wiki_topcats_001_cm_size.pdf}
\caption[CM pipeline on the wiki\_topcats  network and its model LFR graph for r=0.001]{\textbf{CM pipeline on the empirical wiki\_topcats network and its model LFR graph for r=0.001.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:wikitopcats-cm-lfr-001}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/wiki_topcats_cm_steps_lfr01.pdf}
\includegraphics[width=0.37\textwidth]{figs/wiki_topcats_01_cm_size.pdf}
\caption[CM pipeline on the wiki\_topcats  network and its model LFR graph for r=0.01]{\textbf{CM pipeline on the empirical wiki\_topcats  network and its model LFR graph for r=0.01.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:wikitopcats-cm-lfr-01}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/wiki_topcats_cm_steps_lfr1.pdf}
\includegraphics[width=0.37\textwidth]{figs/wiki_topcats_1_cm_size.pdf}
\caption[CM pipeline on the wiki\_topcats  network and its model LFR graph for r=0.1]{\textbf{CM pipeline on the empirical wiki\_topcats network and its model LFR graph for r=0.1.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:wikitopcats-cm-lfr-1}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/wiki_topcats_cm_steps_lfr5.pdf}
\includegraphics[width=0.37\textwidth]{figs/wiki_topcats_5_cm_size.pdf}
\caption[CM pipeline on the wiki\_topcats s network and its model LFR graph for r=0.5]{\textbf{CM pipeline on the empirical wiki\_topcats network and its model LFR graph for r=0.5.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:wikitopcats-cm-lfr-5}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/wiki_talk_cm_steps_lfr001.pdf}
\includegraphics[width=0.37\textwidth]{figs/wiki_talk_001_cm_size.pdf}
\caption[CM pipeline on the Wikipedia talk network and its model LFR graph for r=0.001]{\textbf{CM pipeline on the empirical Wikipedia talk network and its model LFR graph for r=0.001.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:wikitalk-cm-lfr-001}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/wiki_talk_cm_steps_lfr01.pdf}
\includegraphics[width=0.37\textwidth]{figs/wiki_talk_01_cm_size.pdf}
\caption[CM pipeline on the Wikipedia talk network and its model LFR graph for r=0.01]{\textbf{CM pipeline on the empirical Wikipedia talk network and its model LFR graph for r=0.01.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:wikitalk-cm-lfr-01}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/wiki_talk_cm_steps_lfr1.pdf}
\includegraphics[width=0.37\textwidth]{figs/wiki_talk_1_cm_size.pdf}
\caption[CM pipeline on the Wikipedia talk network and its model LFR graph for r=0.1]{\textbf{CM pipeline on the empirical Wikipedia talk network and its model LFR graph for r=0.1.} The left panel shows the community size distribution in each step of running CM and the right panel shows a comparison between the community size distribution of the original Leiden clustering, the LFR ground-truth communities and the Leiden clustering of the LFR network.}
\label{fig:wikitalk-cm-lfr-1}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.62\textwidth]{figs/wiki_talk_cm_steps_lfr5.pdf}
\includegraphics[width=0.37\textwidth]{figs/wiki_talk_5_cm_size.pdf}
\caption[CM pipeline on the Wikipedia talk network for r=0.5]{\textbf{CM pipeline on the empirical Wikipedia talk network for r=0.5.} The left panel shows the community size distribution in each step of running CM and the right panel shows the community size distribution of the original Leiden clustering. For this network, we were not able to generate a corresponding LFR graph, and therefore the second row is empty.}
\label{fig:wikitalk-cm-lfr-5}
\end{figure}
\clearpage
\bibliographystyle{apalike}
\bibliography{cmv1}
\end{document}


\clearpage

\begin{table}[ht]
\centering
\begin{tabular}{rrrrrr}
  \hline
  k value & clus count & node cov & min & med & max       \\ \hline
  10      & 2569       & 23.6     & 11  & 40  & 6,650,349 \\
  \hline
\end{tabular}
\caption[IKC clusters for the Open Citations Network]{\textbf{IKC clusters  for the Open Citations Network} The Open Citations Network (Materials and Methods) consisting of 75,025,194 nodes and 1,363,605,603 edges was clustered with the IKC algorithm using a k value of 10.
Node coverage is the percentage of nodes in the network found in clusters of size at least 11. Minimum, median, and max cluster sizes, restricted to clusters of size at least 11, are shown in the last three columns. }
\label{tab:IKC-11-OC-basicstats}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{lrrrrrr}
  \hline
  clustering & k\_value & clus\_count & node\_cov & min & med & max \\ \hline
  IKC        & 10       & 3999        & 19.5      & 11  & 45  & 6,650,087 \\
  \hline
\end{tabular}
\caption[Identifying well connected clusters from IKC clustering of the OC]{\textbf{Identifying well connected clusters from IKC clustering of the Open Citations network} Following the same procedure as Leiden, the clusters were limited to those of size 11 or greater, then depleted of trees, then processed by CM, and then filtered to remove any clusters of size 10 or less as well as trees. However, this result excludes three large (size 100,000+) clusters of IKC for which CM could not run. In order to make CM scalable to the OpenCitations network, we processed all clusters above size 100,000 individually through CM and processed all clusters size 100,000 or below as one clustering through CM. There were 19 clusters that were greater than size 100,000, of which 3 clusters failed to run through CM. The CM results of the 16 clusters were combined with the CM result of the clusters size 100,000 or below to produce the final clustering whose cluster statistics are reported in the table.}
\label{tab:CM-IKC-11-OC-basicstats}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{rrrrrr}
  \hline
  k value & clus count & node cov & min & med & max       \\ \hline
  10       & 128         & 3.8       & 14  & 79  & 214,877 \\
  \hline
\end{tabular}
\caption[IKC clusters  for the CEN]{\textbf{IKC clusters of size at least 11 for the CEN} The Curated Exososome Network was clustered with the IKC algorithm using a k value of 10.
Node coverage is the percentage of nodes in the network found in clusters. Minimum, median, and max cluster sizes are shown in the last three columns.}
\label{tab:IKC-11-CEN-basicstats}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{lrrrrrr}
  \hline
  clustering & k\_value & clus\_count & node\_cov & min & med & max \\ \hline
  IKC        & 10       & 187         & 3.8       & 14  & 64  & 214,850 \\
  \hline
\end{tabular}
\caption[Identifying well connected clusters from IKC clustering of the CEN]{\textbf{Identifying well connected clusters from IKC clustering of the CEN} .}
\label{tab:CM-IKC-11-CEN-basicstats}
\end{table}

\begin{figure}[h!]
\centering
\includegraphics[width=0.37\textwidth]{figs/oc_ikc_istouched.pdf}
\caption[IKC Clusters of the Open Citations Network Impacted by CM]{\textbf{IKC Clusters of the Open Citations Network (OC) Impacted by CM}. For IKC followed by CM processing, each bar shows the total number of clusters. The fraction of the clusters that are affected by the CM processing is colored in red and the fraction in blue are for those that are not affected by the CM processing (because their min cut size is at least that large). Overall, 6.38\% of the input IKC clusters had small edge cuts.}
\label{fig:ocistouched-ikc}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width=0.37\textwidth]{figs/cen_ikc_istouched.pdf}
\caption[IKC Clusters of the CEN with small edge cuts]{\textbf{IKC Clusters of the Curated Exosome Network (CEN) with small edge cuts}. For IKC followed by CM processing, each bar shows the total number of clusters. The fraction of the clusters that have small edge cuts is colored in red and the fraction in blue are for those that do not have small edge cuts. Overall, 1.41\% of the input IKC clusters have small edge cuts.}
\label{fig:cenistouched-ikc}
\end{figure}

\clearpage
