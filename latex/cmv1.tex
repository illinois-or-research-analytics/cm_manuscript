\documentclass[12pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{textcomp}
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
\usepackage{caption}
\usepackage{subcaption}								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{color}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{url}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\usepackage{natbib}
\usepackage{xcolor}
% removed hyperref because of arXiv complaining
\usepackage{authblk}
\usepackage{float}
\usepackage{rotating}
\usepackage{adjustbox}
\usepackage[font=small,labelfont=bf]{caption}
%\usepackage{changes}
\usepackage{changes}
\definechangesauthor[name={George Chacko}, color=blue]{gc}

\usepackage{authblk}
\title{Finding Well-Connected Communities in Real-World Networks}
\author[1]{Minhyuk Park\thanks{author order to be determined later}}
\author[1]{Yasamin Tabatabaee\thanks{author order to be determined later}}
\author[1]{Baqiao Liu\thanks{author order to be determined later}}
\author[2]{Dmitriy Korobskiy}
\author[1,3]{George Chacko\thanks{warnow@illinois.edu}}
\author[1]{Tandy Warnow\thanks{chackoge@illinois.edu}}
\affil[1]{Department of Computer Science, University of Illinois Urbana-Champaign, Urbana, IL 61801}
\affil[2]{NTT DATA, McLean, VA 22102}
\affil[3]{Office of Research, Grainger College of Engineering, University of Illinois Urbana-Champaign, Urbana, IL 61801}

% \setlength{\parindent}{0pt}
%SetFonts

% ORCID IDs

% Baqiao Liu: 0000-0002-4210-8269
% Tandy Warnow: 0000-0001-7717-3514
% George Chacko: 0000-0002-2127-1892

\begin{document}
\maketitle
	
\abstract{Community detection in real-world networks is a basic step in scientometrics research, and is typically addressed through the use of
graph clustering methods that partition the vertices of a network into disjoint subsets.
While  the formal definition for ``community" vary across methods, it is well accepted that a community should be well-connected, so that the deletion of a small
number of edges should not disconnect the community.
Here, we evaluate how well-connected the clusters are that are produced using two 
 approaches for graph clustering -- the Leiden software using different resolution parameters
and Iterative k-core clustering (Wedell et al., QSS 2022). 
We find that both methods produce clusters that are poorly connected when applied to real-world networks, but this is especially true for Leiden when run
with small resolution parameter values.
We present a new pipeline for use with these clustering methods that guarantees that the output clusters will be well-connected, and explore its use
on a collection of real world networks, including several citation networks, and their  corresponding synthetic LFR networks.
Used with Leiden and IKC, our study suggests that only a fraction (ranging from x\% to 80\%) of  the  vertices in real world networks are found in 
well-connected communities containing at least 11 vertices.
Interestingly, when applied to the corresponding synthetic LFR networks, a different pattern is observed: most of the network is 
contained in well-connected clusters containing at least 11 vertices.
Since the LFR network generation process by definition assumes that every vertex is in a community, this 
study suggests the possibility that community structure is not globally found within real-world networks, and that clusters produced by
standard methods should be post-processed to evaluate whether they satisfy criteria for being a valid community.
The pipeline we provide is tunable to allow the user to specify the criteria for a valid community in terms of (a)  a lower bound on the community size and (b) the 
minimum edge cut size as a function of the cluster size. 
}
	
\clearpage
	
\section{Introduction} 

Community detection in large networks has applications throughout scientometrics, including the detection of emerging research areas, authorship communities, etc.
The problem of finding communities in large networks has been posed as a {\em graph partitioning} problem, where the input is a graph (i.e., a network with vertices and edges) and the
objective is a partitioning of the vertices into disjoint subsets, so that each of the subsets defines a community.
While variations of this formulation appear (e.g., in some cases overlapping communities are sought, and in other cases additional meta data may be available to assist in community
detection), this is a common approach to community detection that has been used in many studies (cites).

While a formal definition for what constitutes a community is not fully agreed upon, most research supports the assumption that a community will be {\em well-connected}, which
can be formulated as saying that for a cluster to define a valid community, it  should not have a small edge cut (i.e., there should not be a small set of edges whose deletion disconnects
the cluster); see discussion in
\cite{Traag_2019}. 
While the minimum size of an edge cut is a matter that can be debated, two formulations have been proposed for this.
The first approach simply requires that an edge cut be above some size that depends on the number $n$ of vertices in the cluster, such as $\log_{10}(n)$. 
This is a relatively weak bound for large values of $n$, but does provide some constraints on small clusters (e.g., a tree cluster with ten or more vertices would be considered to be poorly connected).  
The second approach, which is used in providing guarantees for the Leiden clustering, evaluates the size of an edge cut by the split  of the cluster into two parts produces when the edge cut is removed from a cluster, and requires that the
edge cut size be at least a fraction of the number of possible edges between the two  parts.
As proven in \cite{Traag_2019} (Equation D1 in the supplementary information), 
given any optimal CPM clustering of a network using resolution parameter $\gamma$, if an edge cut $E_0$
separates a cluster into two sets $A$ and $B$, then the edge cut has at least $\gamma ||A|| \times ||B||$, where
$||.||$ indicates the number of vertices in the given set.
This is a strong guarantee for large clusters,  but as it depends on the value for $\gamma$, it may have no guarantee on small clusters (below, for example, 
$\sqrt \frac{2}{\gamma}$).

Given the importance of communities being well-connected, we performed a study to evaluate the question of whether clusters produced by different clustering methods
were consistently found to be well-connected.
We used a collection of real-world networks in our study, including some citation graphs but also including networks from SNAP \citep{leskovec2016snap}.





\section{Materials and Methods}

\subsection{Materials}

\paragraph{SNAP}

\paragraph{LFR}


	
\subsection{Methods} 

The custom-implemented ETL process was designed to process a publicly available COCI, the OpenCitations Index of Crossref open DOI-to-DOI citations dump and load it into PostgreSQL RDBMS. 
The Citation data (CSV) is downloaded from \url{https://opencitations.net/download#coci} and unzipped. After that, the custom ETL script, written in Bash and SQL, works as follows:
Finds all CSV files and pipes them in parallel using GNU Parallel command-line utility to the load function
The number of parallel jobs was capped at 20 on a 64 CPU core, 128 GB VM to prevent overloading the machine or Postgres server.
%The load function then loads an individual CSV file into a staging view via psql: \\copy stg_open_citations(oci, citing, cited, creation, timespan, journal_sc, author_sc) from '${absolute_file_path}' (FORMAT CSV, HEADER ON)
The staging view is a stub (empty) view that uses a custom INSTEAD OF INSERT trigger to process (transform) a single citation record.
The trigger does the following citation record processing:
Converting creation to the DATE data type
Converting timespan to the INTERVAL data type
Handling duplicate records (by the oci key). There are a few duplicate oci -s in COCI source data. The logic updates an existing citation record with the processed data. Correspondingly, the last processed duplicate "wins."
A SQL script was used to clean the data by eliminating:
Self-citations: from a DOI to the same DOI
Parallel edges: two or more citations from a DOI A to the same DOI B. No instances of parallel edges were found in the dataset processed.
A SQL DDL statement extracts all unique publication DOIs into a separate table and indexes DOIs using a zero-based integer index to facilitate clustering.
The DOIs were checked for case differences. No duplicate DOIs differing in case only were found in the dataset processed.
\subsection{Data} 
\section{Results and Discussion}
	
\begin{figure}[H]
\centering
\begin{subfigure}[t]{0.48\textwidth}
\centering
%\includegraphics[width=0.9\linewidth]{fig7_overlapping_m.pdf}
\caption{AOC\_m}
%\caption{Generic fig2 a caption} \label{fig:2a}
\end{subfigure}
\hfill
\begin{subfigure}[t]{0.48\textwidth}
\centering
%\includegraphics[width=0.9\linewidth]{fig7_overlapping_k.pdf} 
\caption{AOC\_k}
\end{subfigure}
\caption{}
\label{fig:overlapping}
\end{figure}
		
\section{Conclusions}
	
\section*{Competing Interests} \vspace{3mm} The authors have no competing interests. 
	
\section*{Funding Information} 
	
\section*{Data Availability} 
	
\section*{Acknowledgments} 

\bibliographystyle{apalike}
\bibliography{references}
\end{document}


